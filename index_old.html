<!-- Basic template taken from Mozilla foundation HTML guide-->

<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Rohan Banerjee</title>
  </head>
  <body>
    <h1>Rohan Banerjee</h1>
    
    <img src="pics/profilepic.jpeg" height="200px" />
   
    <h2>Education</h2>

    <p>M.Eng., Electrical Engineering and Computer Science (MIT), 2019
        <br/> Thesis title: <i>Development of a Simulation-Based Platform for Autonomous Vehicle Algorithm Validation </i>
    </p>
    <p>S.B., Electrical Engineering and Computer Science (MIT), 2018</p>


    <h2>Projects</h2>
    <ul>
        <li>3D Point Cloud Clustering Using Small-Variance Asymptotics [6.882, Spring 2018] </li>
        <ul>
            <li> Authors: Rohan Banerjee </li>
            <li> Abstract: Robotic mapping and localization problems rely upon building an accurate model of the environment based on available sensor data (mapping) and using landmarks in the environment to accurately determine the position of the robot (localization). Point clouds, which are collections of 3D points, are a common data format generated from 3D LIDAR sensors. In order to make point cloud data useful to mapping and localization algorithms, we need to meaningfully characterize the structure of the point clouds in a low-dimensional way.

            As a first step towards characterizing point cloud structure, we apply small-variance asymptotics clustering algorithms to two Dirichlet Process models <!-- from [5] --> - a DP-GMM model, which is used to model point densities, and a DP-vMF-MM model, which is used to model surface densities. We then verify the robustness of inference for both models by measuring the sensitivity of inference to changes in the underlying number of clusters and in the noise associated with each cluster in toy datasets. </li>
            <!-- include report -->
        </ul>
        <!-- 6.141: include link to website, final project video, come up with my own "abstract" -->
        <li>Team Project: Robotics: Science and Systems I [6.141, Spring 2018] </li>
        <li>Team Project: Detecting and Reducing Duplicate Posts Among StackExchange Users [6.867, Fall 2017]</li>
        <ul>
            <li> Authors: Rohan Banerjee, Ryan Chung, Isaac Kontomah </li>
            <li> Abstract: This paper seeks to classify duplicate questions in a QA forum. We use the StackExchange dataset, which is comprised of data from 12 different fields including android development, english language, gaming, gis, mathematica, physics, programming, statistics, tex, unix, web design, and wordpress. We tested features pulled from the title, body and author of the post to predict duplicates. Our best model, the neural network, was able to classify testset duplicate posts with a maximum accuracy of 86.95% across all subforums. We were able to identify these duplicates using classifiers trained on these features. We assessed the importance of adding reputation features, namely user reputation and post score, by comparing the performance of our system both with and without these features. Using this tool, we hope to identify potential duplicate posts in StackExchange for moderators to assess and streamline this QA platform. </li>
            <!-- include report (if teammates are ok with it?) -->
        </ul>
        <li>Towards the Development of a Conversational Robotic System with Audio-Visual Localization Capabilities [SuperUROP, 2017]</li>
        <ul>
            <li> Authors: Rohan Banerjee, Jim Glass </li>
            <li> Abstract: Robotic systems that can interact with humans have the potential to fill an important niche in situations that are inherently time-consuming or tedious for humans, such as in healthcare. One component of the human-robot interaction problem involves robotic participation in human spoken conversation, where a robot would effectively respond to verbal instructions and non-verbal cues. In this study, we aim to demonstrate the feasibility of a static system that can localize a speaking subject using a combination of audio and visual localization techniques. We show that the Voice Activity Detector module has the potential for a high speech classification accuracy under certain conditions, while the visual and audio localization modules exhibit tradeoffs between accuracy and range that motivate sensor fusion techniques for producing a source estimate. These results lay the groundwork for the future development of a low-cost enhancement to the Baxter robotic research platform that performs speaker localization, which would allow the platform to engage in conversations with humans. </li>
            <!-- SuperUROP project: include final paper -->
        </ul>
    </ul>
    <h2>Teaching Experience</h2>
    <ul>
        <li>
            Fall 2020: TA for Introduction to Machine Learning (CS 4780/5780)
        </li>
        <li>
            Spring 2018, Fall 2018: TA for Introduction to Probability (6.041/6.431)
        </li>
    </ul>
    <h2>CV/Resume</h2>
    <p> NOTE: last updated in Fall 2019. </p>
    <ul>
        <li> 
            <a href="docs/Banerjee_CV.pdf"> CV </a>
        </li>
        <li>
            <a href="docs/Banerjee_Resume.pdf"> Resume </a>
        </li>
    </ul>
  </body>
</html>


